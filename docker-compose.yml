version: '3.8'

services:
  # PostgreSQL with TimescaleDB extension
  postgres:
    image: timescale/timescaledb:latest-pg14
    environment:
      POSTGRES_DB: calai_dev
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/priv/repo/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and real-time features
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Phoenix backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "4000:4000"
    environment:
      DATABASE_URL: postgres://postgres:postgres@postgres:5432/calai_dev
      REDIS_URL: redis://redis:6379
      SECRET_KEY_BASE: your_secret_key_base_here_replace_in_production
      PHX_HOST: localhost
      PHX_PORT: 4000
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
      - backend_deps:/app/deps
      - backend_build:/app/_build
    command: mix phx.server

  # React Native Metro bundler
  metro:
    build:
      context: ./app
      dockerfile: Dockerfile.dev
    ports:
      - "8081:8081"
    volumes:
      - ./app:/app
      - app_node_modules:/app/node_modules
    command: npx react-native start --reset-cache

  # AI Training environment (optional)
  ai-trainer:
    build:
      context: ./ai
      dockerfile: Dockerfile
    volumes:
      - ./ai:/workspace
      - ai_models:/workspace/models
      - ai_datasets:/workspace/datasets
    environment:
      - PYTHONPATH=/workspace
    profiles:
      - training
    command: python -c "print('AI training environment ready')"

  # Model serving for WASM compilation
  model-server:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./ai/exported_models:/usr/share/nginx/html/models
      - ./deploy/nginx.conf:/etc/nginx/conf.d/default.conf
    profiles:
      - models

volumes:
  postgres_data:
  redis_data:
  backend_deps:
  backend_build:
  app_node_modules:
  ai_models:
  ai_datasets:

networks:
  default:
    name: calai_network
